{
    "paper_id": "00a8b68a4d57d777135ab12f54f12ab057fe38f5",
    "metadata": {
        "title": "Emotion monitoring with RFID: an experimental study",
        "authors": [
            {
                "first": "Qian",
                "middle": [],
                "last": "Xu",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Xuan",
                "middle": [],
                "last": "Liu",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Juan",
                "middle": [],
                "last": "Luo",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "\u00b7",
                "middle": [
                    "Zhenzhong"
                ],
                "last": "Tang",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Emotion recognition can be helpful in many fields such as elderly healthcare. Existing emotion recognition approaches are usually based on wearable sensors or computer vision analysis, which are intrusive or inconvenient to use. In recent years, radio frequency identification (RFID) has been exploited to monitor physiological signs (e.g., respiration and heartbeat) of users in a contactless and convenient way. Motivated by such progresses, we conduct an experimental study on recognizing the emotion of users with commercial RFID devices. We propose Free-EQ, an emotion recognition framework which first extracts respiration-based features and heartbeat-based features from RFID signals and then uses these features to train a classifier to recognize different emotions of a target user. Experiments on commercial RFID hardware show that Free-EQ can distinguish different emotions with relatively high accuracy.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Emotion recognition has a significant impact on improving the interaction between machine and human, such as smart home that can adaptively adjust the setting according to human emotions. Recently, radio frequency identification (RFID) has been used to perform contactless vital signs monitoring of people, e.g., respiration and heartbeat Zhao et al. (2018) and Hou et al. (2017) . By analyzing the collected respiration and average heart rate, according to the interaction of emotion and physiological signals, the goal of emotion recognition can be achieved by analyzing the training feature data Adib et al. (2015) .",
            "cite_spans": [
                {
                    "start": 339,
                    "end": 357,
                    "text": "Zhao et al. (2018)",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 362,
                    "end": 379,
                    "text": "Hou et al. (2017)",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 599,
                    "end": 617,
                    "text": "Adib et al. (2015)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "Motivation"
        },
        {
            "text": "At present, many researches on emotion recognition methods have been proposed, and some of them are in practice. Among them, the audio-visual method of emotional expression is the mainstream technology of emotional recognition, that is, facial expression, body movement and speech to identify human emotions Kahou et al. (2016) , Cowie et al. (2001) and PPG (2017) . The other part is to use physiological means to achieve the purpose, which requires users to wear special physiological sensors (PPGBrugarolas et al. 2016; Jia et al. (2016) ; ECGKahou et al. 2016, etc) . Recently, some researchers have tried to measure heart rate through a smartphone camera (Gregoski et al. (2012) and Lagido et al. (2014) ), which requires users to put their fingertips on the camera. Both methods have their limitations. Audio visual technology only uses the external expression of emotion and cannot accurately judge the inner feelings Picard et al. (2001) . There are situations in which facial expressions can be controlled or body movements can be reduced to change the system's recognition of someone's emotional state. There are also some significant limitations in the use of physiological signals in emotion recognition. One is that it is very troublesome to use special sensors, expensive equipment and intrusion into users' lives to disturb users' emotional state, which makes this method not suitable for long-term and extensive use. Second, it is a very difficult task to map physiological patterns to specific emotional states Kim and Andre (2008) .",
            "cite_spans": [
                {
                    "start": 308,
                    "end": 327,
                    "text": "Kahou et al. (2016)",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 330,
                    "end": 349,
                    "text": "Cowie et al. (2001)",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 354,
                    "end": 364,
                    "text": "PPG (2017)",
                    "ref_id": null
                },
                {
                    "start": 495,
                    "end": 522,
                    "text": "(PPGBrugarolas et al. 2016;",
                    "ref_id": null
                },
                {
                    "start": 523,
                    "end": 540,
                    "text": "Jia et al. (2016)",
                    "ref_id": "BIBREF12"
                },
                {
                    "start": 543,
                    "end": 569,
                    "text": "ECGKahou et al. 2016, etc)",
                    "ref_id": null
                },
                {
                    "start": 660,
                    "end": 683,
                    "text": "(Gregoski et al. (2012)",
                    "ref_id": "BIBREF7"
                },
                {
                    "start": 688,
                    "end": 708,
                    "text": "Lagido et al. (2014)",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 925,
                    "end": 945,
                    "text": "Picard et al. (2001)",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 1528,
                    "end": 1548,
                    "text": "Kim and Andre (2008)",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "Motivation"
        },
        {
            "text": "On the other hand, the biggest advantage of using physiological signals for emotion recognition is that vital signs are more related to people's inner feelings, because it takes advantage of the interaction between autonomic nervous system and heart rhythm Quintana et al. (2012) . In daily life, invasive methods using special equipment are not suitable for continuous long-term monitoring. Therefore, the research of non-contact emotion recognition monitoring method based on wireless becomes more and more urgent. Some systems rely on expensive or special broadband hardware, which makes them unable to carry out large-scale and long-term deployment, such as Doppler radar Droitcour et al. (2009) , UWB radar, FMCW radar Adib et al. (2014) , ZigBee and Wi-Fi signals can also be used to obtain human physiological signals to achieve the purpose of emotion recognition, but these systems require users to be close to the line of sight(LOS) path, and their performance deteriorates near the Fresnel boundary Wang et al. (2016) . In addition, these systems usually have multiple users, even if both users have different emotional states, it is difficult to know who a signal belongs to, which hinders further personalized services.",
            "cite_spans": [
                {
                    "start": 257,
                    "end": 279,
                    "text": "Quintana et al. (2012)",
                    "ref_id": "BIBREF24"
                },
                {
                    "start": 676,
                    "end": 699,
                    "text": "Droitcour et al. (2009)",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 724,
                    "end": 742,
                    "text": "Adib et al. (2014)",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 1009,
                    "end": 1027,
                    "text": "Wang et al. (2016)",
                    "ref_id": "BIBREF26"
                }
            ],
            "ref_spans": [],
            "section": "Motivation"
        },
        {
            "text": "(1) In device-free case, it is easy to hide breath and heartbeat signals from environmental noise, and RFID is not sensitive to small chest motion because of its long wavelength. Moreover, the RF signal reflected by human body is modulated by respiration and heartbeat. In this paper, before data analysis, the signal is preprocessed and the respiratory and heartbeat signals are extracted by two-step extraction method using the frequency characteristics of respiratory and heartbeat signals to solve Zhao et al. (2018) . (2) The respiratory signal is much stronger than the heartbeat signal, and the heartbeat in the RF signal lacks the peak of the characteristic ECG signal, which makes it more difficult to identify the heartbeat boundary accurately. How to extract the heartbeat signal effectively is also a big challenge. In this paper, the algorithm is designed to reduce the impact of respiration. The acceleration of respiration is smaller than that of heartbeat. The acceleration of RF signal is operated to suppress the respiration signal and emphasize the heartbeat. (3) The respiratory patterns captured by heartbeat and RF reflection are transmitted to an emotion classification subsystem. By consulting the characteristics of heartbeat and respiration recommended in the emotion classification subsystem, and using support vector machine classifier to distinguish different emotional states, RFID technology is used to detect and identify human emotions.",
            "cite_spans": [
                {
                    "start": 502,
                    "end": 520,
                    "text": "Zhao et al. (2018)",
                    "ref_id": "BIBREF29"
                }
            ],
            "ref_spans": [],
            "section": "Challenges"
        },
        {
            "text": "This paper extends the application of RFID in the field of emotion recognition. Our solution uses passive RFID tags to monitor the heartbeat and breath to achieve the purpose of emotion recognition, while achieving a better recognition effect of emotion and physiological signals, that is, directly measuring the interaction between emotion and physiological signals, without requiring users to carry special sensors on their bodies. Not only that, this paper attempts to use the movie watching to stimulate the subjects to get physiological changes to identify their emotional state, obtain the physiological data set of the subjects in the experimental process, find the emotional correlation and specificity through various feature content, and design an emotional classification method. After calculating the features of different feature domains (15 features in total), we try to use the combination of embedded feature selection method Guyon and Elissee (2003) and support vector machine to identify human emotion. This is a more lightweight, scalable and unlimited battery life solution, and RFID tag serial number can effectively distinguish different users, improve personalized services.",
            "cite_spans": [
                {
                    "start": 942,
                    "end": 966,
                    "text": "Guyon and Elissee (2003)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Contributions"
        },
        {
            "text": "In recent years, RFID technology has gradually begun to play its unique role in positioning due to its advantages such as high reading rate of reader, low cost of contactless reading and writing and low tag cost. At present, in the RFID positioning technology research, the absolute positioning development earlier, the research results are remarkable.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "In addition to the application of RFID technology in traditional positioning, the newly developed application fields of RFID technology such as HRV detection Wang et al. (2018) , Ding et al. (2015) and Liu et al. (2017) have brought new opportunities for human emotion identification, because RFID tag is a very lightweight, non-contact sensor, and its identification characteristics can effectively and easily distinguish different human bodies. Free-EQ is inspired by the possibility of monitoring breath and heartbeat based on RFID sensor system and emotion recognition system based on physiological signal.",
            "cite_spans": [
                {
                    "start": 158,
                    "end": 176,
                    "text": "Wang et al. (2018)",
                    "ref_id": "BIBREF27"
                },
                {
                    "start": 179,
                    "end": 197,
                    "text": "Ding et al. (2015)",
                    "ref_id": "BIBREF5"
                },
                {
                    "start": 202,
                    "end": 219,
                    "text": "Liu et al. (2017)",
                    "ref_id": "BIBREF19"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "RF-based breath and heartbeat detection Recent research shows that RF signal is very sensitive to the changes of multipath environment, and the chest fluctuation caused by inhalation-exhalation and heartbeat can adjust the RF signal. Therefore, the heartbeat and respiration can be detected according to the RF signal channel information, without the need for the user to hold or wear any device Zhao et al. (2018) . However, most of the existing RF signal monitoring mechanisms rely on special hardware, such as the use of Doppler radar and FMCW radar to monitor vital signs of respiratory and heart rate. Wi-Fi and ZigBee signals can also be used for breath and heartbeat monitoring Liu et al. (2015) , but these systems require users to be close to LOS path.",
            "cite_spans": [
                {
                    "start": 396,
                    "end": 414,
                    "text": "Zhao et al. (2018)",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 685,
                    "end": 702,
                    "text": "Liu et al. (2015)",
                    "ref_id": "BIBREF18"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Previous research on RFID system used the reported channel information to get the position sensing and activity of something or someone. TagBreathe Hou et al. (2017) uses RFID tags on multiple individuals to detect respiration rate (RR), but it can only monitor respiration and lacks heartbeat monitoring. RFID based human heart rate variability monitoring method RF-ECG Wang et al. (2018) pastes a set of COTS-RFID tags on the chest area of human clothes, but does not detect RR. Free-EQ can not only obtain the respiratory rate of human body, but also extract the heartbeat interval.",
            "cite_spans": [
                {
                    "start": 148,
                    "end": 165,
                    "text": "Hou et al. (2017)",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 371,
                    "end": 389,
                    "text": "Wang et al. (2018)",
                    "ref_id": "BIBREF27"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Vital signal-based emotion recognition The work of emotion recognition system based on physiological signals is divided into two stages: firstly, the physiological signals related to emotion are acquired by sensors; secondly, they input these signals into classifiers to recognize emotion. In the MIT lab, some emotional states can be identified by physiological data, including temperature, heart rate, skin conductivity (SC), muscle activity and RSP speed Healey and Picard (1998) and Picard et al. (2001) . Unfortunately, the existing sensors that can extract these signals are mostly used in clinical scenarios so that they are not suitable for public use.",
            "cite_spans": [
                {
                    "start": 458,
                    "end": 482,
                    "text": "Healey and Picard (1998)",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 487,
                    "end": 507,
                    "text": "Picard et al. (2001)",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Based on the existing research on the detection of physiological signals by frequency signals, Free-EQ does not need users to wear any sensors, but only relies on wireless signals reflected from users' bodies to use two-dimensional emotional model for classification.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "The structure of the system is shown in Fig. 1 , which is divided into four parts: preprocessing, breath extractor, heartbeat extractor and emotion classifier.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 40,
                    "end": 46,
                    "text": "Fig. 1",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Free-EQ overview"
        },
        {
            "text": "The basic idea of the design method is to paste three tags to three specific positions of the volunteers' chest, abdomen, chest and abdomen center. The reader is placed on the human body to collect the original data. During data acquisition, the reader will constantly ask for tags, and the three tags will feed back the phase value of RF signal at a certain time point. Due to the existence of environmental noise, multiple tags are deployed to improve the robustness of the system, because the noise effect of different points is different. The breath or heartbeat component of the signal received from one tag can be hidden, but the breath causes the chest to expand and contract, resulting in compound displacement, and the From the tag feedback information received by the reader, the time phase two-dimensional vector of each tag in a period of time can be obtained.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Free-EQ overview"
        },
        {
            "text": "As shown in Fig. 2 , when the reader antenna is 1 m away from the chest, the RF signals fed back by the three closed tags show regular wavy patterns as the chest moves rhythmically. The 0-43 s signal ripple pattern is clear, the phase value fluctuates significantly, the chest movement caused by respiration corresponds to the figure, and the phase value after 43 s is almost a constant, indicating that volunteers leave the monitoring area. The experimental results show that the signal phase has obvious quasi periodicity without device.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 12,
                    "end": 18,
                    "text": "Fig. 2",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "Free-EQ overview"
        },
        {
            "text": "Based on the above experimental basis, this paper uses signal preprocessing to reduce the impact of environmental noise. The breath and heartbeat extraction module realizes the separation of breath signal and heartbeat signal. The feature extraction module realizes the extraction of emotion related features. The obtained features are input into the emotion classifier for training and ultimately achieve the purpose of human emotion recognition.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Free-EQ overview"
        },
        {
            "text": "Smothing: By analyzing the phase information fed back by the reader, it is found that the phase is folded, termed as wrapped phase. The phase calculation formula is as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Preprocessing"
        },
        {
            "text": "Because the value range of arctangent function is (\u2212 2 , 2 ) , the calculated result is not the actual phase, but the actual phase is the package phase value which is redundant to 2 and folded in an interval, and the difference between the actual phase and the measured result is an integral multiple of 2 , resulting in the periodic multi value problem.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Preprocessing"
        },
        {
            "text": "Phase unwrapping can be realized by adding and subtracting on each pixel according to the phase difference between adjacent pixels. Z (m) represents the folded phase signal, Z u (m) represents the phase signal expanded after operation, so the phase expansion steps are as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Preprocessing"
        },
        {
            "text": "(1) Z (m) = Z u (m);",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Preprocessing"
        },
        {
            "text": "(2) Based on the second point of Z (m) , the difference between the previous point and the current point is calculated \u0394; (3) If \u0394 > 2 , then Z u (m) the current point and all subsequent points minus ;",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Preprocessing"
        },
        {
            "text": "(1) (4) If \u0394 < \u2212 2 , then Z u (m) the current point and all subsequent points plus ; (5) Repeat the above steps until you traverse Z u (m) all points.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Preprocessing"
        },
        {
            "text": "Interpolation: After smoothing, due to the collision between tags, the response of RFID tags is uneven in the time domain. In order to solve this problem, the Lagrangian four point interpolation method is used to obtain the phase flow with the same interval. The interpolation frequency set in the system is 50 Hz. Low interpolation frequency can reduce the computation, but it will reduce the system accuracy.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Preprocessing"
        },
        {
            "text": "where k is a polynomial degree, y i is the function value of point i(i = 1, 2, \u2026 , k + 1) . The general formula of Lagrange interpolation is shown in formula (2), so we can get the unique polynomial f (x) in the complexity of O(k 2 ). After data processing with 50 Hz as interpolation frequency, the reported phase baseline drifts because the propagation distance will be changed by small movements, such as sitting straight or leaning on a chair. Free-eq uses exponentially weighted moving average (EWMA) to remove these trends and make the system environment independent. EWMA increases different weights by a given node, obtains the moving average value according to the given different weights, and determines the prediction value based on the final moving average value. Its weighting coefficient decreases exponentially, and the weighted influence of each node decreases exponentially with time. The closer the current time is, the greater the weighted influence of data is. The recursive formula is as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Preprocessing"
        },
        {
            "text": "where s t is the actual phase value at time t, v t is the weighted mean value at time t, v 1 = s 1 and \u2208 (0, 1) represents the speed of weight decrease, the smaller the value is, the faster the weight decreases. In the optimization algorithm, we usually choose \u2265 0.9 . According to the frequency of respiratory and heartbeat signals (0.1-1.5 Hz), in the actual processing, we set to 0.99, so the amplitude fluctuation of frequency response after the cut-off frequency is relatively small.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Preprocessing"
        },
        {
            "text": "There are three main sources of phase fluctuations from reader feedback, namely, environmental noise, respiration and heartbeat. Among them, the fluctuation caused by",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Breath extractor"
        },
        {
            "text": "respiration and heartbeat is the main one, and the frequency range of respiration and heartbeat is different for different objects. After preprocessing, the noise is randomly distributed in the whole frequency domain. However, most of the energy, i.e. the fluctuation caused by respiration and heartbeat, is concentrated in some frequency range.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Breath extractor"
        },
        {
            "text": "In order to extract the coarse-grained respiratory and heartbeat signals, we collect the prior knowledge of human respiratory rate (RR) and heartbeat rate (HR), the normal RR is 12-20 bpm (0.2-0.33 Hz) and the normal HR is 60-100 bpm (1-1.67 Hz) when the healthy adults are calm. Free-EQ uses fourth-order Butterworth filters with two different cut-off frequencies (FFT to get the frequency range of energy concentration, usually 0.2-0.33 Hz and 1-1.67 Hz). Their frequency response is the most flat, there is no ripple in the passband, and they roll to zero in the stopband. The rough RR and HR signals are reflected in the frequencydomain peaks of these signals.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Breath extractor"
        },
        {
            "text": "In order to obtain the sub-band spectrum of the heartbeat signal and the respiratory signal, after the typical fast Fourier transform is adopted in this paper, the curve in Fig. 3 can clearly reflect the maximum amplitude of the spectrum in the range of 0.2-0.4 Hz and 1-1.2 Hz. Combining the actual respiration and the heartbeat frequency of the human body, the first peak of the spectrum can be the centralized distribution frequency range of the respiratory signal, and the second peak is the heartbeat.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 173,
                    "end": 179,
                    "text": "Fig. 3",
                    "ref_id": null
                }
            ],
            "section": "Breath extractor"
        },
        {
            "text": "Next, we use Butterworth filter to set the above frequency as the cut-off frequency to filter the coarse-grained respiratory signal we need. The filter order is set as 4 in Free-EQ, and the cut-off frequency is 0.2-0.4 Hz. The results are shown in Fig. 4 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 248,
                    "end": 254,
                    "text": "Fig. 4",
                    "ref_id": null
                }
            ],
            "section": "Breath extractor"
        },
        {
            "text": "According to the experimental results, the filtered signals show periodic fluctuations, each of which is roughly the same as a single respiratory cycle of human body. The specific error analysis will be explained in the Sect. 7. 6 Heartbeat extractor",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Breath extractor"
        },
        {
            "text": "The purpose of this processing is to suppress the respiratory signal and improve the signal-to-noise ratio of the heartbeat signal. Recall that the phase of the RF signal is proportional to the composite displacement due to the inspiratory expiratory process and the pulse effect. Because the displacement caused by inspiratory expiratory process is one order of magnitude larger than that caused by heartbeat, the RF phase signal is mainly controlled by respiration. However, the acceleration of respiration is less than that of heartbeat. This is because breathing is usually slow and steady, and the heartbeat includes rapid muscle contraction. Therefore, we can suppress breathing and emphasize heartbeat by operating signals proportional to acceleration rather than displacement.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Enhanced heartbeat"
        },
        {
            "text": "By definition, acceleration is the second derivative of displacement. Using this characteristic, we can simply calculate the second derivative of RF phase signal. Because we Filtering don't have the analytical expression of RF signal, we must calculate the second derivative by numerical method. There are many such numerical methods with different properties. We use the following second-order differentiator because it is robust to noise Holoborodko (2014) , and its general expression is:",
            "cite_spans": [
                {
                    "start": 440,
                    "end": 458,
                    "text": "Holoborodko (2014)",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "Enhanced heartbeat"
        },
        {
            "text": "The parameters in Eq. (4) are as follows:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Enhanced heartbeat"
        },
        {
            "text": "where N \u2265 5 is the filter length (must be odd), M is the center of symmetry, f (x k ) is the function value at point x k , x * is the sample point. The experimental results show that the ideal effect can be achieved when the filter length is 7, so the differentiator can be specified as follows Noise Holoborodko (2014): where f \u2032\u2032 0 refers to the second derivative of a specific sample, f i refers to the distance value of time series i samples, and h is the time interval between consecutive samples. As mentioned in Sect. 4 interpolation, we use 50 Hz interpolation frequency, so that there is one data point every 0.02 s.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Enhanced heartbeat"
        },
        {
            "text": "(",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Enhanced heartbeat"
        },
        {
            "text": "Combined with the experiment, we can set the step h to 0.12 s. In Fig. 5 , we show the original RF signal and the acceleration signal processed by two different differentiators. Figures 6 and 7 respectively show the comparison between the coarse-grained heartbeat signal filtered by the filter in the 1-1.2 Hz frequency band and the acceleration signal obtained by the differential second-order differentiator and the noise robust second-order differentiator. Figure 7 shows that the curve fluctuation of the two is similar. In the acceleration signal, each heartbeat cycle has a periodic mode, and the respiratory effect can be ignored. However, because the signal is noisy and lacks clear features, it is still difficult to describe the beat boundary, so we need to use the heartbeat segmentation algorithm.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 66,
                    "end": 72,
                    "text": "Fig. 5",
                    "ref_id": "FIGREF3"
                },
                {
                    "start": 178,
                    "end": 193,
                    "text": "Figures 6 and 7",
                    "ref_id": "FIGREF4"
                },
                {
                    "start": 460,
                    "end": 468,
                    "text": "Figure 7",
                    "ref_id": null
                }
            ],
            "section": "Enhanced heartbeat"
        },
        {
            "text": "In Free-EQ, the acceleration signal needs to be divided into separate heartbeat. The key challenge is that we don't know the morphology of heartbeat and can't guide the segmentation process. In order to solve this problem, we refer to the optimization algorithm in Zhao et al. (2016) , which can jointly restore the shape and segmentation of heartbeat.",
            "cite_spans": [
                {
                    "start": 265,
                    "end": 283,
                    "text": "Zhao et al. (2016)",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [],
            "section": "Segmentation algorithm of heartbeat"
        },
        {
            "text": "This optimal intuition is that the continuous human heartbeat should have the same shape. Therefore, although they may stretch or compress due to different heartbeat lengths, their overall shape should be the same. This means that we need to find a division to minimize the shape differences between the resulting beats, taking into account that we cannot know the shape of the beat apriori, and that the beat may be compressed or stretched. In addition, our formula is not to use greedy algorithm to seek local optimal selection, but to optimize all possible segments, as follows. Set x = (x 1 , x 2 , \u2026 , x n ) represents a sequence of length N, segment S = s 1 , s 2 , \u2026 is to divide x into non-overlapping continuous subsequences, in which each subsegment s i by | | s i | | points. In order to identify each heartbeat cycle, we need to find a segment to make the segments most similar, that is, to minimize the changes between segments. We use variance as the measurement standard. Since statistical variance is only defined by scalars or vectors with the same dimension, we need to do linear warping for vectors of different lengths which is realized through a cubic spline interpolation (McKinley and Levine (1998) ).",
            "cite_spans": [
                {
                    "start": 1194,
                    "end": 1221,
                    "text": "(McKinley and Levine (1998)",
                    "ref_id": "BIBREF21"
                }
            ],
            "ref_spans": [],
            "section": "Segmentation algorithm of heartbeat"
        },
        {
            "text": "The algorithm Zhao et al. (2016) does not estimate the segmentation point and template at the same time, but fix another template while updating the segmentation point and template. In each iteration, our algorithm updates the segmentation of the given current template, and then updates the template of the given new segmentation. For these two subproblems, our algorithm can get the global optimal solution with a time complexity of O (kn), where k is the number of iterations before the algorithm converges. Because the number of possible segments is limited and the cost function of each iteration decreases monotonically before convergence, the convergence of the algorithm is guaranteed. Finally, it can be found that the global optimization is not guaranteed by the global algorithm, but each subproblem achieves its global optimization. In practice, the convergence speed of the algorithm is very fast, and it can converge to a local optimum. The average number of iterations k is 8, and it is not more than 16. Figure 8 shows the final beat division of the heartbeat signal. As shown in the figure, we have basically successfully divided a single heartbeat sequence and the length of the segment pulse is basically the same as the human heartbeat cycle.",
            "cite_spans": [
                {
                    "start": 14,
                    "end": 32,
                    "text": "Zhao et al. (2016)",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [
                {
                    "start": 1020,
                    "end": 1028,
                    "text": "Figure 8",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Segmentation algorithm of heartbeat"
        },
        {
            "text": "After recovering a single heartbeat from the RF reflex, it uses the human breath pattern and heartbeat interval features to recognize other people's emotions. Next, we describe the emotion model used in this system, and elaborate its feature extraction and classification methods.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Emotion classifier"
        },
        {
            "text": "Emotional modeling: Researchers often use two different methods to simulate emotions. One method is to divide emotions into different categories, that is to say, emotion judgment must be selected from the list of specified tags, such as happy, sad, surprised, angry and so on. one problem of this method is that human emotions may contain mixed emotions of the above tags, because the choice of vocabulary is limited. Another method is to classify emotions from multiple dimensions. Express their impressions of each stimulus on several consecutive scales, such as pleasant and unpleasant, simple and complex, etc. The common scale of this method is price and wake-up. The price represents the pleasure of stimulation, one is positive, the other is negative. Free-EQ chooses the latter to construct a 2D emotional model, which value divides emotions into four states: joy, pleasure, anger and sadness. In the past researches related to human emotion recognition, scholars usually use the value combination of evocation dimension and valence dimension to represent people's emotional state Kim and Andre (2008) and Lang (1995) . In this paper, we explore the four basic emotions in the two-dimensional emotion model, namely, anger, joy, sadness and pleasure. See Sect. 7 for details.",
            "cite_spans": [
                {
                    "start": 1089,
                    "end": 1109,
                    "text": "Kim and Andre (2008)",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 1114,
                    "end": 1125,
                    "text": "Lang (1995)",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [],
            "section": "Emotion classifier"
        },
        {
            "text": "In this paper, we extract features from respiratory signal and heartbeat sequence. There are a lot of literatures on extracting emotion related features from human heartbeat Picard et al. (2001) , Kim and Andre (2008) and Calvo and Dmello (2010) , which can be divided into time-domain analysis, frequency-domain analysis, time-frequency analysis, etc. In this paper, 15 features are extracted from the IBI sequence and respiratory cycle, as shown in Table 1 . Moreover, the system has the function of extracting breath. In order to extract the irregularity of respiration, the peak value detection after low-pass filtering is used to identify each respiratory cycle. Because the time-domain feature is recommended in the past work, the time-domain feature is selected in the experiment Picard et al. (2001) .",
            "cite_spans": [
                {
                    "start": 174,
                    "end": 194,
                    "text": "Picard et al. (2001)",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 197,
                    "end": 217,
                    "text": "Kim and Andre (2008)",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 222,
                    "end": 245,
                    "text": "Calvo and Dmello (2010)",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 787,
                    "end": 807,
                    "text": "Picard et al. (2001)",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [
                {
                    "start": 451,
                    "end": 458,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Feature extraction"
        },
        {
            "text": "Because we only calculate these features based on signal analysis, there may be redundant features in the calculated features, which are essentially independent of the classification of four emotion types. This garbage feature will eventually degrade the performance of the emotion classifier. Combined with the above literature, the use of all these features in the case of limited training data may lead to over fitting. Selecting some of the most relevant features can not only reduce the amount of data needed for training, but also improve the classification accuracy of test data.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature extraction"
        },
        {
            "text": "We choose to use 1-normal SVM Zhu et al. (2003) , which can select a subset of relevant features and get better sparse solution when training SVM classifier.",
            "cite_spans": [
                {
                    "start": 30,
                    "end": 47,
                    "text": "Zhu et al. (2003)",
                    "ref_id": "BIBREF30"
                }
            ],
            "ref_spans": [],
            "section": "Feature extraction"
        },
        {
            "text": "Implementation. The Free-EQ consists of an Impinj R420 commercial reader, several antennas and UHF passive Tag. The antenna model is Laird S9028PCR, and the tag model is AZ-9654. The computer is equipped with Intel (R) core (TM) IU-5200U CPU@2.20 GHz and 16 GB of memory.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Experitmental setup"
        },
        {
            "text": "Setup In our experiment, there were a female participant and a male participant, who wore daily clothes with different fabrics. The experiment was carried out in the room with pure experimental environment. The assessment environment includes office furniture, including desks, seats and computers. The distance from antenna plane to human chest tag is 1 m. Due to the human body impedance, it will cause errors in RFID measurement. In the experiment, there is a solid paper strip with a thickness of 1 cm between the tag and the human body. The three tags are respectively located Lake et al. (2002) , DFA Penzel et al. (2003) Fig. 9 The system experimental setup in the abdomen, the upper part of the abdomen and the middle of the ribs, and the antenna plane is set 1 m away from the chest. Figure 9 shows the working scene of the system measurement.",
            "cite_spans": [
                {
                    "start": 582,
                    "end": 600,
                    "text": "Lake et al. (2002)",
                    "ref_id": "BIBREF16"
                },
                {
                    "start": 603,
                    "end": 627,
                    "text": "DFA Penzel et al. (2003)",
                    "ref_id": null
                },
                {
                    "start": 633,
                    "end": 634,
                    "text": "9",
                    "ref_id": null
                }
            ],
            "ref_spans": [
                {
                    "start": 793,
                    "end": 801,
                    "text": "Figure 9",
                    "ref_id": null
                }
            ],
            "section": "Experitmental setup"
        },
        {
            "text": "In this paper, the peak estimation method is used to calculate the period of respiratory signal, and the respiratory frequency of the measurer is controlled at 18 bpm by respiratory training method. First, we compare the estimated respiratory period of the system with the given period. Figure 10a shows the scatter diagram, where the X and Y coordinates are the period calculated by the wave peak (defined as peak circle) and the period calculated by the wave peak (through circle), respectively. The color represents the density of the midpoint in a specific area. The diagonal represents the standard respiratory cycle of 3.33 s, and the distance to the diagonal is proportional to the error. The experimental scatter diagram shows that all the points are evenly distributed on both sides of the diagonal, and the points close to the diagonal are relatively dense, so the respiratory cycle can be estimated accurately.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 287,
                    "end": 297,
                    "text": "Figure 10a",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Error estimation of respiratory cycle"
        },
        {
            "text": "We quantitatively evaluate the errors in the Fig. 10b , which shows the cumulative distribution function (CDF) of the difference between the coarse-grained respiratory cycle estimates obtained by the two-step extraction method and the cycle estimates obtained based on respiratory training. Figure 10b shows the CDF calculated by the period of wave crest on the left and the CDF calculated by the period of wave trough on the right. The error of the 97th percentile is 0.091 s in the left figure and 0.079 s in the right figure. In our experiment, the average values of peak circle and through circle are 3.3394 s and 3.3365 s, respectively. The average values of the two errors are 0.0129 s and 9.4386e\u221204 s, respectively. Therefore, the estimated cycle length is within 0.39% and 0.03% of its correct value.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 45,
                    "end": 53,
                    "text": "Fig. 10b",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 291,
                    "end": 301,
                    "text": "Figure 10b",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Error estimation of respiratory cycle"
        },
        {
            "text": "In this section, we will study whether the system can accurately classify human emotions according to the RF signals reflected by the human body. It is difficult to obtain highquality data for sentiment analysis, especially in identifying basic real emotions. Therefore, it is very important to design the experiment carefully. Our experiment is based on the previous research on emotion recognition using physiological signals Picard et al. (2001) and Kim and Andre (2008) . Specifically, before the experiment, the subjects prepared stimuli (such as personal memory, music, photos and videos) separately. During the experiment, the subjects sat in the laboratory alone. In this paper, the video was used to trigger some emotional state of the subjects, and the changes of the subjects' expressions were recorded by the camera as the basis of the emotional state. At the same time, the single experiment was completed, and the subjects reported The period when she or he develops this emotional state. In combination with the two, data were collected at the corresponding time period and marked as the emotions reported by the subjects.",
            "cite_spans": [
                {
                    "start": 428,
                    "end": 448,
                    "text": "Picard et al. (2001)",
                    "ref_id": "BIBREF23"
                },
                {
                    "start": 453,
                    "end": 473,
                    "text": "Kim and Andre (2008)",
                    "ref_id": "BIBREF14"
                }
            ],
            "ref_spans": [],
            "section": "Evaluation of emotion recognition"
        },
        {
            "text": "In the frequency domain of HRV time series, scholars are generally interested in three frequency bands: VLF band range 0.003-0.04 Hz, LF band range 0.04-0.15 Hz and HF band range 0.15-0.4 Hz Kim and Andre (2008 Scatter of respiratory cycle estimation frequency component is related to parasympathetic nerve, while the low frequency component is related to both sympathetic and parasympathetic nerve. From these subband spectra, we integrate the power spectral density (PSD) obtained by Welch algorithm and Burg algorithm, and the ratio of power in LF band to power in HF band (LF/HF). Because parasympathetic activity is dominant in heart failure, it is generally believed that LF/HF ratio can distinguish sympathetic effect from parasympathetic effect Malliani (1999) . Figure 11 shows the IBI-PSD of the experimenter at one time. Under the 50% cross validation, the results of individual independent emotion classification are shown in Table 1 system can judge whether a subject is in a state of calm or not. Only from the data of the subject, the average accuracy is 83.3%.",
            "cite_spans": [
                {
                    "start": 191,
                    "end": 210,
                    "text": "Kim and Andre (2008",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 753,
                    "end": 768,
                    "text": "Malliani (1999)",
                    "ref_id": "BIBREF20"
                }
            ],
            "ref_spans": [
                {
                    "start": 771,
                    "end": 780,
                    "text": "Figure 11",
                    "ref_id": "FIGREF0"
                },
                {
                    "start": 938,
                    "end": 945,
                    "text": "Table 1",
                    "ref_id": "TABREF0"
                }
            ],
            "section": "Evaluation of emotion recognition"
        },
        {
            "text": "For the recognition of four emotional states, i.e. sadness, anger, ease and happiness, under the 50% cross validation, the four classification results of individual independent emotions are shown in Table 2 . Only from the data of the subjects, the average accuracy rate was 54.8%. Table 2 shows the confusion matrix between the predicted results and the actual results. By observing the four matrices, it can be found that the prediction of calmness and other emotional states can not be well distinguished. There are two possible results: one is that the model is not accurate due to the small amount of other emotional data, and the other is that the obtained heartbeat IBI value is not reined enough, leading to the characteristics. Table 3 and Table 4 show the evaluation criteria for the results of two and four categories of emotion. We list 7 indicators, such as correctly and incorrectly classified instances, kappa statistics and mean absolute error. Obviously, the binary classification model is better than the polychotomous in each index.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 199,
                    "end": 206,
                    "text": "Table 2",
                    "ref_id": null
                },
                {
                    "start": 282,
                    "end": 289,
                    "text": "Table 2",
                    "ref_id": null
                },
                {
                    "start": 737,
                    "end": 744,
                    "text": "Table 3",
                    "ref_id": null
                },
                {
                    "start": 749,
                    "end": 756,
                    "text": "Table 4",
                    "ref_id": null
                }
            ],
            "section": "Evaluation of emotion recognition"
        },
        {
            "text": "This paper designs and implements a cots-rfid based device to recognize human emotions by reflecting wireless signals to his or her body. This system uses a series of signal processing technology to separate breath and heartbeat, extracts signals from human tiny movement and noise, and uses related algorithm to obtain heartbeat rhythm segmentation sequence.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "We have carried out some experiments in typical scenarios, and the experimental results obtained from the existing data show that the system is reliable and robust. In the case of no equipment, the average error of the system is less than 0.39% and 0.03% for the period estimation of respiratory signal (peak and trough), and the average accuracy of the result of emotion classification is 83.3% . The system also offers the possibility of many other applications, such as remote and long-term vital signs monitoring and stress level assessment. We believe that this marks an important step in the new field of emotion recognition. It is also based on people's growing interest in the use of wireless systems and radio-frequency signal sensing. Therefore, this paper extends the scope of radio-frequency sensing to the field of emotion recognition.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "In addition, although this paper has realized the human emotion recognition by radio frequency, but now it is in the special period of new coronavirus, the insufficient and incomplete experimental data will lead to the decrease of Power spectral density diagram of IBI the accuracy of the system, but there will be more precise emotion recognition by supplementary work in the future ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Networked systems design and implementation",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Adib",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Kabelac",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Katabi",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "317--329",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Smart homes that monitor breathing and heart rate",
            "authors": [
                {
                    "first": "F",
                    "middle": [],
                    "last": "Adib",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Mao",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Kabelac",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Human factors in computing systems",
            "volume": "",
            "issn": "",
            "pages": "837--846",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Wearable heart rate sensor systems for wireless canine health monitoring",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Brugarolas",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Latif",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Dieffenderfer",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "IEEE Sens. J",
            "volume": "16",
            "issn": "10",
            "pages": "3454--3464",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Affect detection: an interdisciplinary review of models, methods, and their applications",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "A"
                    ],
                    "last": "Calvo",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "K"
                    ],
                    "last": "Dmello",
                    "suffix": ""
                }
            ],
            "year": 2010,
            "venue": "IEEE Trans. Affect. Comput",
            "volume": "1",
            "issn": "1",
            "pages": "18--37",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Emotion recognition in human-computer interaction",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Cowie",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Douglascowie",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Tsapatsoulis",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "IEEE Signal Process. Mag",
            "volume": "18",
            "issn": "1",
            "pages": "32--80",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "FEMO: a platform for freeweight exercise monitoring with RFIDs. In: International conference on embedded networked sensor systems",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Ding",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Shangguan",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Yang",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "141--154",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Signal-to-noise ratio in Doppler radar system for heart and respiratory rate measurements",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Droitcour",
                    "suffix": ""
                },
                {
                    "first": "O",
                    "middle": [],
                    "last": "Boriclubecke",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [
                        "T"
                    ],
                    "last": "Kovacs",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "IEEE Trans. Microw. Theory Tech",
            "volume": "57",
            "issn": "10",
            "pages": "2498--2507",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Development and validation of a smartphone heart rate acquisition application for health promotion and wellness telehealth applications",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "J"
                    ],
                    "last": "Gregoski",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Mueller",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Vertegel",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Int. J. Telemed. Appl",
            "volume": "2012",
            "issn": "",
            "pages": "1--7",
            "other_ids": {}
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "An introduction to variable and feature selection",
            "authors": [
                {
                    "first": "I",
                    "middle": [],
                    "last": "Guyon",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Elisseeff",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "J. Mach. Learn. Res",
            "volume": "3",
            "issn": "",
            "pages": "1157--1182",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Digital processing of affective signals",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Healey",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "W"
                    ],
                    "last": "Picard",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "International conference on acoustics speech and signal processing",
            "volume": "",
            "issn": "",
            "pages": "3749--3752",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Noise robust differentiators for second derivative estimation",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Holoborodko",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "TagBreathe: Monitor breathing with commodity RFID systems",
            "authors": [
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Hou",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Zheng",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "International conference on distributed computing systems",
            "volume": "",
            "issn": "",
            "pages": "404--413",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "HB-phone: a bed-mounted geophonebased heartbeat monitoring system. In: Information processing in sensor networks",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Jia",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Alaziz",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Chi",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "1--12",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "EmoNets: Multimodal deep learning approaches for emotion recognition in video",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "E"
                    ],
                    "last": "Kahou",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Bouthillier",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Lamblin",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "J. Multimodal User Interfaces",
            "volume": "10",
            "issn": "2",
            "pages": "99--111",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Emotion recognition based on physiological changes in music listening",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Andre",
                    "suffix": ""
                }
            ],
            "year": 2008,
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "volume": "30",
            "issn": "12",
            "pages": "2067--2083",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Using the smartphone camera to monitor heart rate and rhythm in heart failure patients",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "B"
                    ],
                    "last": "Lagido",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Lobo",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [
                        "R"
                    ],
                    "last": "Leite",
                    "suffix": ""
                }
            ],
            "year": 2014,
            "venue": "Biomedical and health informatics",
            "volume": "",
            "issn": "",
            "pages": "556--559",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Sample entropy analysis of neonatal heart rate variability",
            "authors": [
                {
                    "first": "D",
                    "middle": [
                        "E"
                    ],
                    "last": "Lake",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "S"
                    ],
                    "last": "Richman",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "P"
                    ],
                    "last": "Griffin",
                    "suffix": ""
                }
            ],
            "year": 2002,
            "venue": "Am. J. Physiol. Regul. Integr. Comp. Physiol",
            "volume": "283",
            "issn": "3",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "The emotion probe: studies of motivation and attention",
            "authors": [
                {
                    "first": "P",
                    "middle": [
                        "J"
                    ],
                    "last": "Lang",
                    "suffix": ""
                }
            ],
            "year": 1995,
            "venue": "Am. Psychol",
            "volume": "50",
            "issn": "5",
            "pages": "372--385",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Tracking vital signs during sleep leveraging off-the-shelf WiFi",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "Mobile ad hoc networking and computing",
            "volume": "",
            "issn": "",
            "pages": "267--276",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "Tag-compass: Determining the spatial direction of an object with small dimensions",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Liu",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "International conference on computer communications",
            "volume": "",
            "issn": "",
            "pages": "1--9",
            "other_ids": {}
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "The pattern of sympathovagal balance explored in the frequency domain",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Malliani",
                    "suffix": ""
                }
            ],
            "year": 1999,
            "venue": "Physiology",
            "volume": "14",
            "issn": "3",
            "pages": "111--117",
            "other_ids": {}
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Cubic spline interpolation",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mckinley",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Levine",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Coll. Redw",
            "volume": "45",
            "issn": "1",
            "pages": "1049--1060",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Comparison of detrended fluctuation analysis and spectral analysis for heart rate variability in sleep and sleep apnea",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Penzel",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "W"
                    ],
                    "last": "Kantelhardt",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Grote",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "IEEE Trans. Biomed. Eng",
            "volume": "50",
            "issn": "10",
            "pages": "1143--1151",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "Toward machine emotional intelligence: analysis of affective physiological state",
            "authors": [
                {
                    "first": "R",
                    "middle": [
                        "W"
                    ],
                    "last": "Picard",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Vyzas",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Healey",
                    "suffix": ""
                }
            ],
            "year": 2001,
            "venue": "IEEE Trans. Pattern Anal. Mach. Intell",
            "volume": "23",
            "issn": "10",
            "pages": "1175--1191",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Heart rate variability is associated with emotion recognition: direct evidence for a relationship between the autonomic nervous system and social cognition",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Quintana",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "J"
                    ],
                    "last": "Guastella",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Outhred",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "Int. J. Psychophysiol",
            "volume": "86",
            "issn": "2",
            "pages": "168--172",
            "other_ids": {}
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Heart rate variability: a noninvasive electrocardiographic method to measure the autonomic nervous system",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sztajzel",
                    "suffix": ""
                }
            ],
            "year": 2004,
            "venue": "Swiss Med. Wkly",
            "volume": "134",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Human respiration detection with commodity wifi devices: do user location and body orientation matter? Ubiquitous computing",
            "authors": [
                {
                    "first": "H",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Ma",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "25--36",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "RF-ECG: heart rate variability assessment based on COTS RFID tag array",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Xie",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Bu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lu",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the ACM on interactive, mobile, wearable and ubiquitous technologies",
            "volume": "85",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1145/3214288."
                ]
            }
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Emotion recognition using wireless signals",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Adib",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Katabi",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "ACM/IEEE international conference on mobile computing and networking",
            "volume": "",
            "issn": "",
            "pages": "95--108",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "CRH: A contactless respiration and heartbeat monitoring system with COTS RFID Tags",
            "authors": [
                {
                    "first": "R",
                    "middle": [],
                    "last": "Zhao",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Wang",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Sensor, mesh and ad hoc communications and networks",
            "volume": "",
            "issn": "",
            "pages": "1--9",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "1-norm Support vector machines",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Zhu",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Rosset",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Tibshirani",
                    "suffix": ""
                }
            ],
            "year": 2003,
            "venue": "Neural information processing systems",
            "volume": "",
            "issn": "",
            "pages": "49--56",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Freeof the body caused by the heartbeat can be reflected in the phase change extracted from other tags.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Time-phase diagram of three tags. The above image depicts the human body reflected RF signals read by three tags. The RF signal fluctu-",
            "latex": null,
            "type": "figure"
        },
        "FIGREF2": {
            "text": "FFT Waveform",
            "latex": null,
            "type": "figure"
        },
        "FIGREF3": {
            "text": "Comparison of signal processed by two differentiators with the original signal. This figure shows the original RF signal (top), the signal acceleration calculated by the differential second-order differentiator (called Diff, middle), and the signal acceleration calculated by the noise robust secondorder differentiator (",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "Comparison",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Segmentation",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "CDF of error in Respiratory cycle(a) (b) Fig. 10 Error estimation of respiratory cycle",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Fig. 11 Power spectral density diagram of IBI",
            "latex": null,
            "type": "figure"
        },
        "TABREF0": {
            "text": "Signal correlation characteristics used in Free-EQ",
            "latex": null,
            "type": "table"
        },
        "TABREF1": {
            "text": "). The high",
            "latex": null,
            "type": "table"
        },
        "TABREF2": {
            "text": "Actual (b): anger, sadness, pleasure, joy Classification accuracy: 61.2903% Evaluation of binary classification results Evaluation of polychotomous classification results",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "Conflict of interest The authors declare that there is no conflict of interest regarding the publication of this paper. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Compliance with ethical standards"
        }
    ]
}